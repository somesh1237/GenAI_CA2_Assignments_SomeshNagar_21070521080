{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somesh1237/GenAI_CA2_Assignments_SomeshNagar_21070521080/blob/main/Auto_Regressive_Model_Diffusion_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5aDIIoj1UgF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 1**"
      ],
      "metadata": {
        "id": "eeDirJog1gLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/Auto_Regressive_Model_Diffusion_Model_V_1.0.xlsx'\n",
        "\n",
        "data = pd.read_excel(file_path, sheet_name='Base_Data_Set')"
      ],
      "metadata": {
        "id": "8WT7aLBh1lgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['Symptoms - 1', 'Symptoms - 2', 'Symptoms - 3', 'Other Symptoms']]"
      ],
      "metadata": {
        "id": "sVjlC4po2Edv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symptom_dict = {}"
      ],
      "metadata": {
        "id": "iWvYXxu72U9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2\n",
        "Create a Program that uses the Parser\n",
        "Read the DataSet and Create a Dictionary and store it in memory for reference\n",
        "Refer to the dataset below\n",
        "Print the Loss i.e. Dictionary colums those were not found\n",
        "Read the DataSet and enhance the Dictionary for the new data found in other Symptoms"
      ],
      "metadata": {
        "id": "Qcm7-ZMv2WlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_symptoms(row, symptom_dict):\n",
        "    \"\"\"Parses symptoms from a row and updates the dictionary.\"\"\"\n",
        "    symptoms = {\n",
        "        'Symptoms - 1': row['Symptoms - 1'],\n",
        "        'Symptoms - 2': row['Symptoms - 2'],\n",
        "        'Symptoms - 3': row['Symptoms - 3'],\n",
        "        'Other Symptoms': row['Other Symptoms']\n",
        "    }\n",
        "\n",
        "    for symptom_name, symptom_value in symptoms.items():\n",
        "        if pd.notna(symptom_value):  # Only add non-NaN values\n",
        "            if symptom_name not in symptom_dict:\n",
        "                symptom_dict[symptom_name] = set()\n",
        "            symptom_dict[symptom_name].add(symptom_value)"
      ],
      "metadata": {
        "id": "rJa0JCR_2Zps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_dict(symptom_dict):\n",
        "    \"\"\"Displays the current state of the symptom dictionary.\"\"\"\n",
        "    for symptom, variations in symptom_dict.items():\n",
        "        print(f\"{symptom}: {', '.join(variations)}\")"
      ],
      "metadata": {
        "id": "yPam9SH72en-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_missing_columns(symptom_dict, expected_columns):\n",
        "    \"\"\"Checks and prints missing columns (loss).\"\"\"\n",
        "    missing_columns = [col for col in expected_columns if col not in symptom_dict]\n",
        "    if missing_columns:\n",
        "        print(f\"Missing columns (Loss): {missing_columns}\")\n",
        "    else:\n",
        "        print(\"All expected columns are present.\")\n"
      ],
      "metadata": {
        "id": "13nY6_aE2exB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in data.iterrows():\n",
        "    parse_symptoms(row, symptom_dict)"
      ],
      "metadata": {
        "id": "SL3LStaR2jeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Initial Symptom Dictionary:\")\n",
        "display_dict(symptom_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhmmufSv2qNf",
        "outputId": "557b79b1-36ac-4219-eeed-a701f4a17163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Symptom Dictionary:\n",
            "Symptoms - 1: Y, Mild, Fever\n",
            "Symptoms - 2: Cough, N, Mild\n",
            "Symptoms - 3: N, Cold, Mild\n",
            "Other Symptoms: Sickness, Shivering, Vertigo, Body Ache, Vertigo, Nausia, Text, Head Ache, Nausia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expected_columns = ['Symptoms - 1', 'Symptoms - 2', 'Symptoms - 3', 'Other Symptoms']\n",
        "check_missing_columns(symptom_dict, expected_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nilU3ZK720i5",
        "outputId": "d8b4b6c1-e6b4-4f2c-934f-5e615e988654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All expected columns are present.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in data.iterrows():\n",
        "    parse_symptoms(row, symptom_dict)\n"
      ],
      "metadata": {
        "id": "a8aq8vvE23uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nEnhanced Symptom Dictionary:\")\n",
        "display_dict(symptom_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXd-4tOX26Cu",
        "outputId": "e67c8350-aeb7-4b89-c68e-3aec4a48cfbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enhanced Symptom Dictionary:\n",
            "Symptoms - 1: Y, Mild, Fever\n",
            "Symptoms - 2: Cough, N, Mild\n",
            "Symptoms - 3: N, Cold, Mild\n",
            "Other Symptoms: Sickness, Shivering, Vertigo, Body Ache, Vertigo, Nausia, Text, Head Ache, Nausia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3z9KMZ2k27-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3\n",
        "Print the Loss found in Step 2 and Enhanced Dictionary in the Step 2\n",
        "Enhance the dictionary\n",
        "Attach attributes to the dictionary elements\n",
        "Loss of attributes is 0"
      ],
      "metadata": {
        "id": "T7YwCUtn29fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "symptom_dict = {\n",
        "    \"S1\": {\"Fever\": [\"mild\", \"low\", \"high\"]},\n",
        "    \"S2\": {\"Cough\": [\"mild\", \"low\", \"high\"]},\n",
        "    \"S3\": {\"Cold\": [\"mild\", \"low\", \"high\"]},\n",
        "    \"S4\": {\"Body Ache\": {}},\n",
        "    \"S5\": {\"Cold\": {}},\n",
        "    \"S6\": {\"Shivering\": [\"mild\", \"high\", \"intermittent\"]}\n",
        "}"
      ],
      "metadata": {
        "id": "RbT_tSAt28VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define function to parse, print Loss, and enhance the dictionary\n",
        "def print_loss_and_enhance_dictionary(data, symptom_dict):\n",
        "    loss = []  # Track missing attributes\n",
        "    for _, row in data.iterrows():\n",
        "\n",
        "        # Check if the column name is 'SrNo' or 'Sr.No'\n",
        "        sr_no = row.get('SrNo') if 'SrNo' in row else row.get('Sr.No')\n",
        "\n",
        "        # If sr_no is still None, it means neither column exists\n",
        "        if sr_no is None:\n",
        "            raise KeyError(\"Neither 'SrNo' nor 'Sr.No' column found in the DataFrame.\")\n",
        "\n",
        "        patient_id = row['Patient_Id']\n",
        "        observation = row['Observation']\n",
        "        particulars = row['Particulars']\n",
        "        time_period = row['Time Period']\n",
        "        location = row[['City', 'State', 'Country', 'Pincode']].to_dict()\n",
        "\n",
        "        # If there is a valid observation, check against the dictionary\n",
        "        if pd.notna(observation):\n",
        "            symptoms = observation.split(\", \")\n",
        "            for symptom in symptoms:\n",
        "                found = False\n",
        "                for key, symptom_data in symptom_dict.items():\n",
        "                    if symptom in symptom_data:\n",
        "                        # Symptom found, attach attributes (only to dictionary types)\n",
        "                        if isinstance(symptom_data[symptom], dict):\n",
        "                            symptom_dict[key][symptom].update({\n",
        "                                \"Particulars\": particulars,\n",
        "                                \"Time Period\": time_period,\n",
        "                                \"Location\": location\n",
        "                            })\n",
        "                        found = True\n",
        "                        break\n",
        "                if not found:\n",
        "                    loss.append((sr_no, patient_id, symptom))  # Track loss if symptom not found\n",
        " # Print the loss in Step 2\n",
        "    print(\"Loss found in Step 2:\")\n",
        "    if loss:\n",
        "        for sr_no, patient_id, symptom in loss:\n",
        "            print(f\"SrNo: {sr_no}, Patient_Id: {patient_id}, Symptom: {symptom} (Not found in dictionary)\")\n",
        "    else:\n",
        "        print(\"No loss found. All symptoms matched the dictionary.\")\n"
      ],
      "metadata": {
        "id": "Kp6jE-Bx28X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the enhanced dictionary\n",
        "print(\"\\nEnhanced Symptom Dictionary:\")\n",
        "for key, symptoms in symptom_dict.items():\n",
        "  print(f\"{key}: {symptoms}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOaUmmsJ28bU",
        "outputId": "318925aa-87ef-42a1-829f-0136b0466e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enhanced Symptom Dictionary:\n",
            "S1: {'Fever': ['mild', 'low', 'high']}\n",
            "S2: {'Cough': ['mild', 'low', 'high']}\n",
            "S3: {'Cold': ['mild', 'low', 'high']}\n",
            "S4: {'Body Ache': {}}\n",
            "S5: {'Cold': {}}\n",
            "S6: {'Shivering': ['mild', 'high', 'intermittent']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_loss_of_attributes(symptom_dict):\n",
        "    attribute_loss = 0\n",
        "    for key, symptoms in symptom_dict.items():\n",
        "        for symptom, details in symptoms.items():\n",
        "            if isinstance(details, dict):\n",
        "                required_keys = [\"Particulars\", \"Time Period\", \"Location\"]\n",
        "                if any(key not in details for key in required_keys):\n",
        "                    attribute_loss += 1\n",
        "\n",
        "    print(f\"\\nLoss of attributes is {attribute_loss}\")\n",
        "    if attribute_loss == 0:\n",
        "        print(\"No attribute loss, all attributes were correctly attached.\")"
      ],
      "metadata": {
        "id": "DgMHaUAC3l-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_loss_of_attributes(symptom_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRTuVhY63mBy",
        "outputId": "2dcb41ad-1b4d-4e8f-81fa-1eacc7548256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loss of attributes is 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4\n",
        "Parser is nearly ableto\n",
        "1\tRead any format of data csv,tsv,json,xml\n",
        "2\tReads and enhances dictionary\n",
        "3\tIn next pass reads the data and prints as per the available colums in dictonary\n",
        "4\tUse a facility to dump the dictionary as file\n",
        "5\tAllow manual editing and reparsing of dictionary"
      ],
      "metadata": {
        "id": "Xi0wfK-43sya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n"
      ],
      "metadata": {
        "id": "mdV_k02t3ykD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SymptomParser:\n",
        "    def __init__(self):\n",
        "        self.symptom_dict = {}\n",
        "        self.loss = []\n",
        "        self.loss_of_attributes = 0  # Initialize loss of attributes\n",
        "\n",
        "    def read_data(self, file_path):\n",
        "        \"\"\"Reads data from various formats and enhances the dictionary.\"\"\"\n",
        "        file_extension = os.path.splitext(file_path)[1]\n",
        "\n",
        "        if file_extension == '.csv':\n",
        "            self.read_csv(file_path)\n",
        "        elif file_extension == '.tsv':\n",
        "            self.read_tsv(file_path)\n",
        "        elif file_extension == '.json':\n",
        "            self.read_json(file_path)\n",
        "        elif file_extension == '.xml':\n",
        "            self.read_xml(file_path)\n",
        "        else:\n",
        "            print(\"Unsupported file format.\")\n",
        "\n",
        "    def read_csv(self, file_path):\n",
        "        df = pd.read_csv(file_path)\n",
        "        self.enhance_dictionary(df)\n",
        "\n",
        "    def read_tsv(self, file_path):\n",
        "        df = pd.read_csv(file_path, sep='\\t')\n",
        "        self.enhance_dictionary(df)\n",
        "\n",
        "    def read_json(self, file_path):\n",
        "        with open(file_path) as f:\n",
        "            data = json.load(f)\n",
        "            df = pd.json_normalize(data)\n",
        "            self.enhance_dictionary(df)\n",
        "\n",
        "    def read_xml(self, file_path):\n",
        "        tree = ET.parse(file_path)\n",
        "        root = tree.getroot()\n",
        "        data = []\n",
        "\n",
        "        # Convert XML to a list of dictionaries\n",
        "        for item in root.findall('.//item'):  # Adjust the tag based on your XML structure\n",
        "            entry = {}\n",
        "            for child in item:\n",
        "                entry[child.tag] = child.text\n",
        "            data.append(entry)\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "        self.enhance_dictionary(df)\n",
        "\n",
        "    def enhance_dictionary(self, df):\n",
        "        \"\"\"Enhances the dictionary based on the DataFrame.\"\"\"\n",
        "        for index, row in df.iterrows():\n",
        "            for column, value in row.items():\n",
        "                if column not in self.symptom_dict:\n",
        "                    self.symptom_dict[column] = set()\n",
        "                self.symptom_dict[column].add(value)\n",
        "\n",
        "        self.loss_of_attributes = 0  # Reset the loss of attributes\n",
        "\n",
        "    def dump_dictionary(self, filename):\n",
        "        \"\"\"Dumps the dictionary to a JSON file.\"\"\"\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(self.symptom_dict, f, indent=4)\n",
        "\n",
        "    def print_dictionary(self):\n",
        "        \"\"\"Prints the symptom dictionary in a structured format.\"\"\"\n",
        "        print(\"\\nSymptom Dictionary:\")\n",
        "        for key, value in self.symptom_dict.items():\n",
        "            print(f\"\\t'{key}': {list(value)}\")\n",
        "\n",
        "    def manual_editing(self):\n",
        "        \"\"\"Allows manual editing of the dictionary.\"\"\"\n",
        "        while True:\n",
        "            print(\"\\nCurrent Dictionary:\")\n",
        "            self.print_dictionary()\n",
        "            edit_key = input(\"\\nEnter the key to edit (or type 'exit' to finish): \")\n",
        "            if edit_key.lower() == 'exit':\n",
        "                break\n",
        "\n",
        "            if edit_key in self.symptom_dict:\n",
        "                new_values = input(\"Enter new values (comma separated): \")\n",
        "                self.symptom_dict[edit_key] = set(new_values.split(\",\"))\n",
        "            else:\n",
        "                print(\"Key not found. Try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = SymptomParser()\n",
        "\n",
        "    print(\"1. Read and Create Dictionary\")\n",
        "    file_path = input(\"Enter the data file path (CSV, TSV, JSON, XML): \")\n",
        "    parser.read_data(file_path)\n",
        "\n",
        "    print(f\"Dictionary Loss is: {parser.loss_of_attributes}\")\n",
        "\n",
        "    print(\"2. Dump Dictionary\")\n",
        "    dump_filename = input(\"Enter the filename to save the dictionary (e.g., output.json): \")\n",
        "    parser.dump_dictionary(dump_filename)\n",
        "\n",
        "    print(\"3. Print Data Sets\")\n",
        "    parser.print_dictionary()\n",
        "\n",
        "    print(\"4. Allow editing and reparsing of data\")\n",
        "    parser.manual_editing()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OqBOjv04C8j",
        "outputId": "c26b44ec-15c6-415d-c354-aef2c05eba15"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Read and Create Dictionary\n",
            "Enter the data file path (CSV, TSV, JSON, XML): /content/Auto_Regressive_Model_Diffusion_Model_V_1.0.xlsx\n",
            "Unsupported file format.\n",
            "Dictionary Loss is: 0\n",
            "2. Dump Dictionary\n",
            "Enter the filename to save the dictionary (e.g., output.json): output.json\n",
            "3. Print Data Sets\n",
            "\n",
            "Symptom Dictionary:\n",
            "4. Allow editing and reparsing of data\n",
            "\n",
            "Current Dictionary:\n",
            "\n",
            "Symptom Dictionary:\n",
            "\n",
            "Enter the key to edit (or type 'exit' to finish): exit\n"
          ]
        }
      ]
    }
  ]
}